{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "e:\\study\\Thesis\\epymarl\\src",
    "dependencies": [
      "munch==2.5.0",
      "numpy==1.21.5",
      "sacred==0.8.2",
      "torch==1.13.1"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [
      {
        "commit": "f355a55262ac9afecdb53368fec6337c549cc160",
        "dirty": true,
        "url": "https://github.com/uoe-agents/epymarl.git"
      },
      {
        "commit": "f355a55262ac9afecdb53368fec6337c549cc160",
        "dirty": true,
        "url": "https://github.com/uoe-agents/epymarl.git"
      },
      {
        "commit": "f355a55262ac9afecdb53368fec6337c549cc160",
        "dirty": true,
        "url": "https://github.com/uoe-agents/epymarl.git"
      }
    ],
    "sources": [
      [
        "main.py",
        "_sources\\main_59c64e1d717bfe57002e1d893ee0bce7.py"
      ],
      [
        "run.py",
        "_sources\\run_5089e959db01b1c8206c1da0e246045d.py"
      ],
      [
        "utils\\logging.py",
        "_sources\\logging_5979e105b1df4f81fe662159bb019050.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\site-packages\\wrapt\\wrappers.py\", line 523, in __call__\n    args, kwargs)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\site-packages\\sacred\\config\\captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"e:/study/Thesis/epymarl/src/main.py\", line 40, in my_main\n    run(_run, config, _log)\n",
    "  File \"e:\\study\\Thesis\\epymarl\\src\\run.py\", line 62, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"e:\\study\\Thesis\\epymarl\\src\\run.py\", line 159, in run_sequential\n    learner = le_REGISTRY[args.base_learner](mac, imac, buffer.scheme, logger, args)\n",
    "  File \"e:\\study\\Thesis\\epymarl\\src\\learners\\coma_learner.py\", line 21, in __init__\n    self.icm_learner = ICMLearner(self.imac, scheme, logger, args)\n",
    "  File \"e:\\study\\Thesis\\epymarl\\src\\learners\\icm_learner.py\", line 16, in __init__\n    self.mac = copy.deepcopy(mac)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 307, in _reconstruct\n    value = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 307, in _reconstruct\n    value = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 307, in _reconstruct\n    value = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 307, in _reconstruct\n    value = deepcopy(value, memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\copy.py\", line 161, in deepcopy\n    y = copier(memo)\n",
    "  File \"E:\\Anaconda\\envs\\epymarl\\lib\\site-packages\\torch\\nn\\parameter.py\", line 55, in __deepcopy__\n    result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)\n",
    "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 19.25 MiB already allocated; 1.30 GiB free; 30.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
  ],
  "heartbeat": "2023-06-04T15:21:05.047274",
  "host": {
    "ENV": {},
    "cpu": "Unknown",
    "gpus": {
      "driver_version": "516.01",
      "gpus": [
        {
          "model": "NVIDIA GeForce MX150",
          "persistence_mode": false,
          "total_memory": 2048
        }
      ]
    },
    "hostname": "Jiong",
    "os": [
      "Windows",
      "Windows-10-10.0.22000-SP0"
    ],
    "python_version": "3.7.16"
  },
  "meta": {
    "command": "my_main",
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "env_args.time_limit=500",
        "env_args.key=rware:rware-small-4ag-v1"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2023-06-04T15:19:45.780844",
  "status": "FAILED",
  "stop_time": "2023-06-04T15:21:05.047274"
}